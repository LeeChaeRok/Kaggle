{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_columns = 50\n",
    "# 한글 폰트 설정\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "# 경고창 무시\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터 불러오기\n",
    "credit_df = pd.read_csv(\"credit_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID 열 삭제\n",
    "credit_df = credit_df.drop(columns=['OBS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 992 entries, 0 to 999\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   DURATION           992 non-null    int64  \n",
      " 1   EDUCATION_PURPOSE  992 non-null    int64  \n",
      " 2   SAV_ACCT           992 non-null    int64  \n",
      " 3   EMPLOYMENT         992 non-null    float64\n",
      " 4   INSTALL_RATE       992 non-null    int64  \n",
      " 5   REAL_ESTATE        992 non-null    int64  \n",
      " 6   PROP_UNKN_NONE     992 non-null    int64  \n",
      " 7   OTHER_INSTALL      992 non-null    int64  \n",
      " 8   RENT               992 non-null    int64  \n",
      " 9   FOREIGN            992 non-null    int64  \n",
      " 10  IS_CHK_ACCT        992 non-null    int32  \n",
      " 11  NO_CREDIT_HISTORY  992 non-null    float64\n",
      " 12  DULY_PAY_HISTORY   992 non-null    float64\n",
      " 13  CRITICAL_ACCT      992 non-null    float64\n",
      " 14  IS_SAV_ACCT        992 non-null    int32  \n",
      " 15  IS_MALE            992 non-null    int32  \n",
      " 16  RESPONSE           992 non-null    int64  \n",
      "dtypes: float64(4), int32(3), int64(10)\n",
      "memory usage: 127.9 KB\n"
     ]
    }
   ],
   "source": [
    "credit_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 당좌예금계좌 : 범주형 변수 처리\n",
    "# 3: 당좌계좌 존재 X\n",
    "# 당좌계좌 유무를 새로운 변수로 만듦\n",
    "# 당좌계좌가 존재하지 않는 사람들은 계좌 잔액이 0이므로 0으로 처리 \n",
    "\n",
    "credit_df['IS_CHK_ACCT'] = np.where(credit_df['CHK_ACCT'] == 3, 1, 0)\n",
    "credit_df.loc[credit_df['CHK_ACCT'] == 3, 'CHK_ACCT'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HISTORY: one_hot_encoding\n",
    "one_hot = OneHotEncoder(sparse=False)\n",
    "history_df = pd.DataFrame(one_hot.fit_transform(credit_df[['HISTORY']]))\n",
    "history_df.columns = ['NO_CREDIT_HISTORY', 'DULY_PAY_HISTORY', 'NOW_PAY_HISTORY', 'DELAY_PAY_HISTORY', 'CRITICAL_ACCT']\n",
    "\n",
    "# concat df\n",
    "credit_df = pd.concat([credit_df, history_df], axis=1)\n",
    "credit_df = credit_df.drop(columns=['HISTORY'])\n",
    "\n",
    "#credit_df['IS_CRITICAL'] = np.where(credit_df['HISTORY'] == 4, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PURPOSE: '자산 목적', '교육 목적'\n",
    "credit_df['ASSET_PURPOSE'] = np.where(credit_df['NEW_CAR'] == 1, 1,\n",
    "                             np.where(credit_df['USED_CAR'] == 1, 1,\n",
    "                                 np.where(credit_df['FURNITURE'] == 1, 1,\n",
    "                                     np.where(credit_df['RADIO/TV'] == 1, 1, 0))))\n",
    "\n",
    "credit_df.loc[credit_df['RETRAINING'] == 1,'EDUCATION'] = 1\n",
    "credit_df = credit_df.rename(columns={'EDUCATION' : 'EDUCATION_PURPOSE'})\n",
    "credit_df = credit_df.drop(columns=['NEW_CAR', 'USED_CAR', 'FURNITURE', 'RADIO/TV', 'RETRAINING'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 당좌예금(CHK_ACCT)과 똑같이 처리\n",
    "\n",
    "credit_df['IS_SAV_ACCT'] = np.where(credit_df['SAV_ACCT'] == 4, 1, 0)\n",
    "credit_df.loc[credit_df['SAV_ACCT'] == 4, 'SAV_ACCT'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employment, PRESENT_RESIDENT 범주형 범위 다른데 어떻게?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성별: 남자와 여자로 나누기\n",
    "credit_df['IS_MALE'] = np.where(credit_df['MALE_DIV'] == 1, 1,\n",
    "                             np.where(credit_df['MALE_SINGLE'] == 1, 1,\n",
    "                                 np.where(credit_df['MALE_MAR_or_WID'] == 1, 1, 0)))\n",
    "\n",
    "credit_df = credit_df.drop(columns=['MALE_DIV', 'MALE_SINGLE', 'MALE_MAR_or_WID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직업 유무로 나누기\n",
    "credit_df['IS_JOB'] = np.where(credit_df['JOB'] == 0, 0, 1)\n",
    "\n",
    "credit_df = credit_df.drop(columns=['JOB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 안에서 특별한 패턴을 찾을 수 없었으며\n",
    "# 전체 데이터의 0.8% 밖에 되지 않아, 삭제하더라도 모델의 결과에 영향을 끼치지 않을 것이라고 판단\n",
    "credit_df = credit_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 열 순서 변경\n",
    "temp = credit_df['RESPONSE']\n",
    "credit_df = credit_df.drop(columns=['RESPONSE'])\n",
    "credit_df['RESPONSE'] = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변수 선정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop by t-test:  ['CHK_ACCT', 'AMOUNT', 'CO-APPLICANT', 'GUARANTOR', 'PRESENT_RESIDENT', 'NUM_CREDITS', 'NUM_DEPENDENTS', 'TELEPHONE', 'NOW_PAY_HISTORY', 'DELAY_PAY_HISTORY', 'IS_JOB']\n"
     ]
    }
   ],
   "source": [
    "# levenue: 정규성 유무없이 등분산 검정 가능 \n",
    "# t-test : 정규분포일 때 t 값의 표본분포를 t분포라고 함 t = (표본평균 - 모평균) / 표준오차\n",
    "\n",
    "group1 = credit_df[credit_df['RESPONSE'] == 0]\n",
    "group2 = credit_df[credit_df['RESPONSE'] == 1]\n",
    "drop_col = []\n",
    "ttest_p = 0\n",
    "\n",
    "for col in credit_df.columns[:-1]:\n",
    "    equal_var = stats.levene(group1[col], group2[col])\n",
    "    if equal_var.pvalue > .05:\n",
    "        ttest_p = stats.ttest_ind(group1[col], group2[col], equal_var=True).pvalue\n",
    "    else:\n",
    "        ttest_p = stats.ttest_ind(group1[col], group2[col], equal_var=False).pvalue\n",
    "    \n",
    "    if ttest_p > 0.05:\n",
    "        drop_col.append(col)\n",
    "print(\"Drop by t-test: \", drop_col)\n",
    "\n",
    "credit_df = credit_df.drop(columns=drop_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop by Multicollinearity:  ['AGE', 'OWN_RES', 'ASSET_PURPOSE']\n"
     ]
    }
   ],
   "source": [
    "# 다중공선성\n",
    "\n",
    "drop_col = []\n",
    "for i, col in enumerate(credit_df.columns):\n",
    "    # 다중공선성 10 이상 삭제\n",
    "    if variance_inflation_factor(credit_df.values, i) > 10:\n",
    "        drop_col.append(col)\n",
    "\n",
    "        \n",
    "print(\"Drop by Multicollinearity: \", drop_col)\n",
    "credit_df = credit_df.drop(columns=drop_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 992 entries, 0 to 999\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   DURATION           992 non-null    int64  \n",
      " 1   EDUCATION_PURPOSE  992 non-null    int64  \n",
      " 2   SAV_ACCT           992 non-null    int64  \n",
      " 3   EMPLOYMENT         992 non-null    float64\n",
      " 4   INSTALL_RATE       992 non-null    int64  \n",
      " 5   REAL_ESTATE        992 non-null    int64  \n",
      " 6   PROP_UNKN_NONE     992 non-null    int64  \n",
      " 7   OTHER_INSTALL      992 non-null    int64  \n",
      " 8   RENT               992 non-null    int64  \n",
      " 9   FOREIGN            992 non-null    int64  \n",
      " 10  IS_CHK_ACCT        992 non-null    int32  \n",
      " 11  NO_CREDIT_HISTORY  992 non-null    float64\n",
      " 12  DULY_PAY_HISTORY   992 non-null    float64\n",
      " 13  CRITICAL_ACCT      992 non-null    float64\n",
      " 14  IS_SAV_ACCT        992 non-null    int32  \n",
      " 15  IS_MALE            992 non-null    int32  \n",
      " 16  RESPONSE           992 non-null    int64  \n",
      "dtypes: float64(4), int32(3), int64(10)\n",
      "memory usage: 127.9 KB\n"
     ]
    }
   ],
   "source": [
    "credit_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습, 평가 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 독립변수와 종속변수 분리\n",
    "X = credit_df.drop(columns=['RESPONSE'])\n",
    "y = credit_df['RESPONSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 0.8 // 평가 데이터 0.2 로 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종속변수의 데이터 불균형 해결 위해 SMOTE 사용\n",
    "smote = SMOTE(random_state=1)\n",
    "X_smote_train, y_smote_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sclaer 쓴 이유: \n",
    "scaler = MinMaxScaler()\n",
    "X_scaler_train = scaler.fit_transform(X_train)\n",
    "X_scaler_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(pred):\n",
    "    print(\"정확도: \", accuracy_score(y_test, pred))\n",
    "    print(\"정밀도: \", precision_score(y_test, pred))\n",
    "    print(\"재현율: \", recall_score(y_test, pred))\n",
    "    print(\"ROC score: \", roc_auc_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.486596\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>RESPONSE</td>     <th>  No. Observations:  </th>  <td>   992</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   976</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    15</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 01 Dec 2021</td> <th>  Pseudo R-squ.:     </th>  <td>0.2005</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>19:33:07</td>     <th>  Log-Likelihood:    </th> <td> -482.70</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -603.76</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>5.220e-43</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DURATION</th>          <td>   -0.0233</td> <td>    0.006</td> <td>   -3.906</td> <td> 0.000</td> <td>   -0.035</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EDUCATION_PURPOSE</th> <td>   -0.1847</td> <td>    0.223</td> <td>   -0.828</td> <td> 0.408</td> <td>   -0.622</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SAV_ACCT</th>          <td>    0.4056</td> <td>    0.122</td> <td>    3.337</td> <td> 0.001</td> <td>    0.167</td> <td>    0.644</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EMPLOYMENT</th>        <td>    0.2202</td> <td>    0.064</td> <td>    3.443</td> <td> 0.001</td> <td>    0.095</td> <td>    0.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INSTALL_RATE</th>      <td>   -0.0692</td> <td>    0.057</td> <td>   -1.210</td> <td> 0.226</td> <td>   -0.181</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>REAL_ESTATE</th>       <td>    0.4665</td> <td>    0.187</td> <td>    2.490</td> <td> 0.013</td> <td>    0.099</td> <td>    0.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PROP_UNKN_NONE</th>    <td>   -0.3615</td> <td>    0.224</td> <td>   -1.615</td> <td> 0.106</td> <td>   -0.800</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OTHER_INSTALL</th>     <td>   -0.3392</td> <td>    0.201</td> <td>   -1.684</td> <td> 0.092</td> <td>   -0.734</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RENT</th>              <td>   -0.3720</td> <td>    0.201</td> <td>   -1.855</td> <td> 0.064</td> <td>   -0.765</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>FOREIGN</th>           <td>    1.1702</td> <td>    0.604</td> <td>    1.938</td> <td> 0.053</td> <td>   -0.013</td> <td>    2.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IS_CHK_ACCT</th>       <td>    1.4945</td> <td>    0.191</td> <td>    7.823</td> <td> 0.000</td> <td>    1.120</td> <td>    1.869</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NO_CREDIT_HISTORY</th> <td>   -0.7721</td> <td>    0.388</td> <td>   -1.988</td> <td> 0.047</td> <td>   -1.533</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DULY_PAY_HISTORY</th>  <td>   -0.6431</td> <td>    0.353</td> <td>   -1.821</td> <td> 0.069</td> <td>   -1.335</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRITICAL_ACCT</th>     <td>    0.6719</td> <td>    0.198</td> <td>    3.390</td> <td> 0.001</td> <td>    0.283</td> <td>    1.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IS_SAV_ACCT</th>       <td>    0.9580</td> <td>    0.239</td> <td>    4.007</td> <td> 0.000</td> <td>    0.489</td> <td>    1.427</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IS_MALE</th>           <td>    0.4143</td> <td>    0.171</td> <td>    2.419</td> <td> 0.016</td> <td>    0.079</td> <td>    0.750</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               RESPONSE   No. Observations:                  992\n",
       "Model:                          Logit   Df Residuals:                      976\n",
       "Method:                           MLE   Df Model:                           15\n",
       "Date:                Wed, 01 Dec 2021   Pseudo R-squ.:                  0.2005\n",
       "Time:                        19:33:07   Log-Likelihood:                -482.70\n",
       "converged:                       True   LL-Null:                       -603.76\n",
       "Covariance Type:            nonrobust   LLR p-value:                 5.220e-43\n",
       "=====================================================================================\n",
       "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "DURATION             -0.0233      0.006     -3.906      0.000      -0.035      -0.012\n",
       "EDUCATION_PURPOSE    -0.1847      0.223     -0.828      0.408      -0.622       0.253\n",
       "SAV_ACCT              0.4056      0.122      3.337      0.001       0.167       0.644\n",
       "EMPLOYMENT            0.2202      0.064      3.443      0.001       0.095       0.346\n",
       "INSTALL_RATE         -0.0692      0.057     -1.210      0.226      -0.181       0.043\n",
       "REAL_ESTATE           0.4665      0.187      2.490      0.013       0.099       0.834\n",
       "PROP_UNKN_NONE       -0.3615      0.224     -1.615      0.106      -0.800       0.077\n",
       "OTHER_INSTALL        -0.3392      0.201     -1.684      0.092      -0.734       0.055\n",
       "RENT                 -0.3720      0.201     -1.855      0.064      -0.765       0.021\n",
       "FOREIGN               1.1702      0.604      1.938      0.053      -0.013       2.354\n",
       "IS_CHK_ACCT           1.4945      0.191      7.823      0.000       1.120       1.869\n",
       "NO_CREDIT_HISTORY    -0.7721      0.388     -1.988      0.047      -1.533      -0.011\n",
       "DULY_PAY_HISTORY     -0.6431      0.353     -1.821      0.069      -1.335       0.049\n",
       "CRITICAL_ACCT         0.6719      0.198      3.390      0.001       0.283       1.060\n",
       "IS_SAV_ACCT           0.9580      0.239      4.007      0.000       0.489       1.427\n",
       "IS_MALE               0.4143      0.171      2.419      0.016       0.079       0.750\n",
       "=====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 회귀 모델\n",
    "logit_model = sm.Logit(y, X)\n",
    "logit_result = logit_model.fit()\n",
    "logit_result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.6934673366834171\n",
      "정밀도:  0.7532467532467533\n",
      "재현율:  0.8345323741007195\n",
      "ROC score:  0.6005995203836931\n"
     ]
    }
   ],
   "source": [
    "# 로지스틱 회귀\n",
    "logit = LogisticRegression()\n",
    "logit.fit(X_scaler_train, y_train)\n",
    "logit_pred = logit.predict(X_scaler_test)\n",
    "\n",
    "get_score(logit_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.6934673366834171\n",
      "정밀도:  0.7671232876712328\n",
      "재현율:  0.8057553956834532\n",
      "ROC score:  0.6195443645083932\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 포레스트\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_scaler_train, y_train)\n",
    "rf_pred = rf.predict(X_scaler_test)\n",
    "\n",
    "get_score(rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:33:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "정확도:  0.6683417085427136\n",
      "정밀도:  0.762589928057554\n",
      "재현율:  0.762589928057554\n",
      "ROC score:  0.6062949640287769\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "xg = XGBClassifier()\n",
    "xg.fit(X_scaler_train, y_train)\n",
    "xg_pred = xg.predict(X_scaler_test)\n",
    "\n",
    "get_score(xg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.7085427135678392\n",
      "정밀도:  0.7832167832167832\n",
      "재현율:  0.8057553956834532\n",
      "ROC score:  0.6445443645083933\n"
     ]
    }
   ],
   "source": [
    "# LGBM\n",
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X_scaler_train, y_train)\n",
    "lgbm_pred = lgbm.predict(X_scaler_test)\n",
    "\n",
    "get_score(lgbm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.7085427135678392\n",
      "정밀도:  0.7579617834394905\n",
      "재현율:  0.8561151079136691\n",
      "ROC score:  0.6113908872901679\n"
     ]
    }
   ],
   "source": [
    "# GridSearch \n",
    "param = {'learning_rate': [0.001, 0.01, 0.1],\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_depth': [-1, 10, 20, 50]\n",
    "        }\n",
    "\n",
    "lgbm_grid = GridSearchCV(lgbm, param_grid=param, cv=5, n_jobs=-1,scoring='accuracy')\n",
    "\n",
    "lgbm_grid.fit(X_scaler_train, y_train)\n",
    "lgbm_grid_pred = lgbm_grid.predict(X_scaler_test)\n",
    "\n",
    "get_score(lgbm_grid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm\n",
    "# dnn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
